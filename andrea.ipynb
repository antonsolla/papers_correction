{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Import relevant packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/ae/e2/4dea6313ef2b38442fccbbaf4017e50a6c3c8a50e8ee9b512783e5c90409/joblib-1.4.0-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/4b/35/ff1194913e4b88b95ecaddd8aa6315bc81b97e8f3e2e6ce0dee91c3bb2b1/regex-2024.4.16-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.0 kB 330.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 511.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.4/1.5 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.5 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 13.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.4/268.4 kB 16.1 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 301.2/301.2 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB ? eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.0 nltk-3.8.1 regex-2024.4.16 tqdm-4.66.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nlkt libraries\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstring\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mText_Similarity_Dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Text_Similarity_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîéFirst dataset exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
       "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
       "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
       "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
       "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>be careful how you code a new european directi...</td>\n",
       "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>india seeks to boost construction india has cl...</td>\n",
       "      <td>music mogul fuller sells company pop idol supr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>podcasters  look to net money nasa is doing it...</td>\n",
       "      <td>ukip outspent labour on eu poll the uk indepen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>row over  police  power for csos the police fe...</td>\n",
       "      <td>ban on hunting comes into force fox hunting wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>election  could be terror target  terrorists m...</td>\n",
       "      <td>nhs waiting time target is cut hospital waitin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>japan economy slides to recession the japanese...</td>\n",
       "      <td>optimism remains over uk housing the uk proper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lufthansa flies back to profit german airline ...</td>\n",
       "      <td>applegate s charity show closes us musical swe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>sprinter walker quits athletics former europea...</td>\n",
       "      <td>ferguson urges henry punishment sir alex fergu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>gervais writing simpsons episode the office s ...</td>\n",
       "      <td>no charges against tv s cosby us comedian bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>kenyan school turns to handhelds at the mbita ...</td>\n",
       "      <td>more women turn to net security older people a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>us woman sues over ink cartridges a us woman i...</td>\n",
       "      <td>more power to the people says hp the digital r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>bond game fails to shake or stir for gaming fa...</td>\n",
       "      <td>mobile multimedia slow to catch on there is no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>oscars race enters final furlong the race for ...</td>\n",
       "      <td>label withdraws mcfadden s video the new video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>charvis set to lose fitness bid flanker colin ...</td>\n",
       "      <td>the force is strong in battlefront the warm re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>mobile multimedia slow to catch on there is no...</td>\n",
       "      <td>text messages aid disaster recovery text messa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>us firm  bids for lacroix label  a us firm has...</td>\n",
       "      <td>yukos seeks court action on sale yukos will re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unique_ID                                              text1  \\\n",
       "0           0  savvy searchers fail to spot ads internet sear...   \n",
       "1           1  millions to miss out on the net by 2025  40% o...   \n",
       "2           2  young debut cut short by ginepri fifteen-year-...   \n",
       "3           3  diageo to buy us wine firm diageo  the world s...   \n",
       "4           4  be careful how you code a new european directi...   \n",
       "5           5  india seeks to boost construction india has cl...   \n",
       "6           6  podcasters  look to net money nasa is doing it...   \n",
       "7           7  row over  police  power for csos the police fe...   \n",
       "8           8  election  could be terror target  terrorists m...   \n",
       "9           9  japan economy slides to recession the japanese...   \n",
       "10         10  lufthansa flies back to profit german airline ...   \n",
       "11         11  sprinter walker quits athletics former europea...   \n",
       "12         12  gervais writing simpsons episode the office s ...   \n",
       "13         13  kenyan school turns to handhelds at the mbita ...   \n",
       "14         14  us woman sues over ink cartridges a us woman i...   \n",
       "15         15  bond game fails to shake or stir for gaming fa...   \n",
       "16         16  oscars race enters final furlong the race for ...   \n",
       "17         17  charvis set to lose fitness bid flanker colin ...   \n",
       "18         18  mobile multimedia slow to catch on there is no...   \n",
       "19         19  us firm  bids for lacroix label  a us firm has...   \n",
       "\n",
       "                                                text2  \n",
       "0   newcastle 2-1 bolton kieron dyer smashed home ...  \n",
       "1   nasdaq planning $100m share sale the owner of ...  \n",
       "2   ruddock backs yapp s credentials wales coach m...  \n",
       "3   mci shares climb on takeover bid shares in us ...  \n",
       "4   media gadgets get moving pocket-sized devices ...  \n",
       "5   music mogul fuller sells company pop idol supr...  \n",
       "6   ukip outspent labour on eu poll the uk indepen...  \n",
       "7   ban on hunting comes into force fox hunting wi...  \n",
       "8   nhs waiting time target is cut hospital waitin...  \n",
       "9   optimism remains over uk housing the uk proper...  \n",
       "10  applegate s charity show closes us musical swe...  \n",
       "11  ferguson urges henry punishment sir alex fergu...  \n",
       "12  no charges against tv s cosby us comedian bill...  \n",
       "13  more women turn to net security older people a...  \n",
       "14  more power to the people says hp the digital r...  \n",
       "15  mobile multimedia slow to catch on there is no...  \n",
       "16  label withdraws mcfadden s video the new video...  \n",
       "17  the force is strong in battlefront the warm re...  \n",
       "18  text messages aid disaster recovery text messa...  \n",
       "19  yukos seeks court action on sale yukos will re...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unique_ID                                              text1  \\\n",
       "0             0  savvy searchers fail to spot ads internet sear...   \n",
       "1             1  millions to miss out on the net by 2025  40% o...   \n",
       "2             2  young debut cut short by ginepri fifteen-year-...   \n",
       "3             3  diageo to buy us wine firm diageo  the world s...   \n",
       "4             4  be careful how you code a new european directi...   \n",
       "...         ...                                                ...   \n",
       "4018       4018  labour plans maternity pay rise maternity pay ...   \n",
       "4019       4019  high fuel costs hit us airlines two of the lar...   \n",
       "4020       4020  britons growing  digitally obese  gadget lover...   \n",
       "4021       4021  holmes is hit by hamstring injury kelly holmes...   \n",
       "4022       4022  nuclear dumpsite  plan attacked plans to allow...   \n",
       "\n",
       "                                                  text2  \n",
       "0     newcastle 2-1 bolton kieron dyer smashed home ...  \n",
       "1     nasdaq planning $100m share sale the owner of ...  \n",
       "2     ruddock backs yapp s credentials wales coach m...  \n",
       "3     mci shares climb on takeover bid shares in us ...  \n",
       "4     media gadgets get moving pocket-sized devices ...  \n",
       "...                                                 ...  \n",
       "4018  no seasonal lift for house market a swathe of ...  \n",
       "4019  new media battle for bafta awards the bbc lead...  \n",
       "4020  film star fox behind theatre bid leading actor...  \n",
       "4021  tsunami  to hit sri lanka banks  sri lanka s b...  \n",
       "4022  x factor show gets second series tv talent sho...  \n",
       "\n",
       "[4023 rows x 3 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4023, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßπCleaning text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>savvy searchers fail to spot ads internet sear...</td>\n",
       "      <td>newcastle 2-1 bolton kieron dyer smashed home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>millions to miss out on the net by 2025  40% o...</td>\n",
       "      <td>nasdaq planning $100m share sale the owner of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>young debut cut short by ginepri fifteen-year-...</td>\n",
       "      <td>ruddock backs yapp s credentials wales coach m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>diageo to buy us wine firm diageo  the world s...</td>\n",
       "      <td>mci shares climb on takeover bid shares in us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>be careful how you code a new european directi...</td>\n",
       "      <td>media gadgets get moving pocket-sized devices ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  savvy searchers fail to spot ads internet sear...   \n",
       "1          1  millions to miss out on the net by 2025  40% o...   \n",
       "2          2  young debut cut short by ginepri fifteen-year-...   \n",
       "3          3  diageo to buy us wine firm diageo  the world s...   \n",
       "4          4  be careful how you code a new european directi...   \n",
       "\n",
       "                                               text2  \n",
       "0  newcastle 2-1 bolton kieron dyer smashed home ...  \n",
       "1  nasdaq planning $100m share sale the owner of ...  \n",
       "2  ruddock backs yapp s credentials wales coach m...  \n",
       "3  mci shares climb on takeover bid shares in us ...  \n",
       "4  media gadgets get moving pocket-sized devices ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3833"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the 'text1' contains digit numbers\n",
    "contains_digits1 = df['text1'].apply(lambda x: any(char.isdigit() for char in x))\n",
    "contains_digits1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3824"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if the 'text2' contains digit numbers\n",
    "contains_digits2 = df['text2'].apply(lambda x: any(char.isdigit() for char in x))\n",
    "contains_digits2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>eight hundred and seventy-eight nonillion, fou...</td>\n",
       "      <td>twenty-one octillion, one hundred and three se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>two hundred and two quadrillion, five hundred ...</td>\n",
       "      <td>one octillion, one septillion, five sextillion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sixty-two duodecillion, six hundred and twenty...</td>\n",
       "      <td>twenty-one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>two septillion, six hundred and one sextillion...</td>\n",
       "      <td>six octillion, three hundred and thirty-four s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fifty-two trillion, one hundred and ninety-sev...</td>\n",
       "      <td>two hundred octillion, five hundred and ten se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  eight hundred and seventy-eight nonillion, fou...   \n",
       "1          1  two hundred and two quadrillion, five hundred ...   \n",
       "2          2  sixty-two duodecillion, six hundred and twenty...   \n",
       "3          3  two septillion, six hundred and one sextillion...   \n",
       "4          4  fifty-two trillion, one hundred and ninety-sev...   \n",
       "\n",
       "                                               text2  \n",
       "0  twenty-one octillion, one hundred and three se...  \n",
       "1  one octillion, one septillion, five sextillion...  \n",
       "2                                         twenty-one  \n",
       "3  six octillion, three hundred and thirty-four s...  \n",
       "4  two hundred octillion, five hundred and ten se...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_cleaning(text):\n",
    "    # Ensure that text is a string\n",
    "    text = str(text)\n",
    "    # 1. Removing whitespaces\n",
    "    text = text.strip()\n",
    "    # 2. Lowercasing\n",
    "    digits = ''.join(filter(str.isdigit, text))\n",
    "    if digits:\n",
    "        return num2words(int(digits))\n",
    "    else:\n",
    "        return text\n",
    "    # 3. Changing digits to words\n",
    "    text = num2words(text)\n",
    "    # 4. Removing punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, \" \")\n",
    "    return text\n",
    "\n",
    "# Apply basic_cleaning function to whole dataset\n",
    "df['text1'] = df['text1'].apply(basic_cleaning)\n",
    "df['text2'] = df['text2'].apply(basic_cleaning)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the function remove numbers worked\n",
    "contains_digits1 = df['text1'].apply(lambda x: any(char.isdigit() for char in x))\n",
    "contains_digits1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the function remove numbers worked\n",
    "contains_digits2 = df['text2'].apply(lambda x: any(char.isdigit() for char in x))\n",
    "contains_digits2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>eight hundred and seventy-eight nonillion, fou...</td>\n",
       "      <td>twenty-one octillion, one hundred and three se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>two hundred and two quadrillion, five hundred ...</td>\n",
       "      <td>one octillion, one septillion, five sextillion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sixty-two duodecillion, six hundred and twenty...</td>\n",
       "      <td>twenty-one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>two septillion, six hundred and one sextillion...</td>\n",
       "      <td>six octillion, three hundred and thirty-four s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fifty-two trillion, one hundred and ninety-sev...</td>\n",
       "      <td>two hundred octillion, five hundred and ten se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  eight hundred and seventy-eight nonillion, fou...   \n",
       "1          1  two hundred and two quadrillion, five hundred ...   \n",
       "2          2  sixty-two duodecillion, six hundred and twenty...   \n",
       "3          3  two septillion, six hundred and one sextillion...   \n",
       "4          4  fifty-two trillion, one hundred and ninety-sev...   \n",
       "\n",
       "                                               text2  \n",
       "0  twenty-one octillion, one hundred and three se...  \n",
       "1  one octillion, one septillion, five sextillion...  \n",
       "2                                         twenty-one  \n",
       "3  six octillion, three hundred and thirty-four s...  \n",
       "4  two hundred octillion, five hundred and ten se...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def regex(text):\n",
    "    if isinstance(text, list):\n",
    "        return [re.sub('<[^<]+?->', '', word) for word in text]\n",
    "    else:\n",
    "        return re.sub('<[^<]+?->', '', text)\n",
    "\n",
    "# Tokenized  all rows in both columns\n",
    "df['text1']= df['text1'].apply(regex)\n",
    "df['text2']= df['text2'].apply(regex)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[eight, hundred, and, seventy-eight, nonillion...</td>\n",
       "      <td>[twenty-one, octillion, ,, one, hundred, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[two, hundred, and, two, quadrillion, ,, five,...</td>\n",
       "      <td>[one, octillion, ,, one, septillion, ,, five, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[sixty-two, duodecillion, ,, six, hundred, and...</td>\n",
       "      <td>[twenty-one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[two, septillion, ,, six, hundred, and, one, s...</td>\n",
       "      <td>[six, octillion, ,, three, hundred, and, thirt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[fifty-two, trillion, ,, one, hundred, and, ni...</td>\n",
       "      <td>[two, hundred, octillion, ,, five, hundred, an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  [eight, hundred, and, seventy-eight, nonillion...   \n",
       "1          1  [two, hundred, and, two, quadrillion, ,, five,...   \n",
       "2          2  [sixty-two, duodecillion, ,, six, hundred, and...   \n",
       "3          3  [two, septillion, ,, six, hundred, and, one, s...   \n",
       "4          4  [fifty-two, trillion, ,, one, hundred, and, ni...   \n",
       "\n",
       "                                               text2  \n",
       "0  [twenty-one, octillion, ,, one, hundred, and, ...  \n",
       "1  [one, octillion, ,, one, septillion, ,, five, ...  \n",
       "2                                       [twenty-one]  \n",
       "3  [six, octillion, ,, three, hundred, and, thirt...  \n",
       "4  [two, hundred, octillion, ,, five, hundred, an...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to tokenized\n",
    "def tokenized(text):\n",
    "    if isinstance(text, str):\n",
    "        return word_tokenize(text)\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Tokenized all rows in both columns\n",
    "df['text1'] = df['text1'].apply(tokenized)\n",
    "df['text2'] = df['text2'].apply(tokenized)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[eight, hundred, seventy-eight, nonillion, ,, ...</td>\n",
       "      <td>[twenty-one, octillion, ,, one, hundred, three...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[two, hundred, two, quadrillion, ,, five, hund...</td>\n",
       "      <td>[one, octillion, ,, one, septillion, ,, five, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[sixty-two, duodecillion, ,, six, hundred, twe...</td>\n",
       "      <td>[twenty-one]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[two, septillion, ,, six, hundred, one, sextil...</td>\n",
       "      <td>[six, octillion, ,, three, hundred, thirty-fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[fifty-two, trillion, ,, one, hundred, ninety-...</td>\n",
       "      <td>[two, hundred, octillion, ,, five, hundred, te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  [eight, hundred, seventy-eight, nonillion, ,, ...   \n",
       "1          1  [two, hundred, two, quadrillion, ,, five, hund...   \n",
       "2          2  [sixty-two, duodecillion, ,, six, hundred, twe...   \n",
       "3          3  [two, septillion, ,, six, hundred, one, sextil...   \n",
       "4          4  [fifty-two, trillion, ,, one, hundred, ninety-...   \n",
       "\n",
       "                                               text2  \n",
       "0  [twenty-one, octillion, ,, one, hundred, three...  \n",
       "1  [one, octillion, ,, one, septillion, ,, five, ...  \n",
       "2                                       [twenty-one]  \n",
       "3  [six, octillion, ,, three, hundred, thirty-fou...  \n",
       "4  [two, hundred, octillion, ,, five, hundred, te...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove StopWords\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, list):\n",
    "        return [word for word in text if word.lower() not in stop_words]\n",
    "    else:\n",
    "        tokenized = word_tokenize(text)\n",
    "        without_stopwords = [word for word in tokenized if word.lower() not in stop_words]\n",
    "        return without_stopwords\n",
    "\n",
    "# Remove stopwords from all rows in both columns\n",
    "df['text1'] = df['text1'].apply(remove_stopwords)\n",
    "df['text2'] = df['text2'].apply(remove_stopwords)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique_ID</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>eight hundred seventy-eight nonillion , four h...</td>\n",
       "      <td>twenty-one octillion , one hundred three septi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>two hundred two quadrillion , five hundred for...</td>\n",
       "      <td>one octillion , one septillion , five sextilli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sixty-two duodecillion , six hundred twenty-tw...</td>\n",
       "      <td>twenty-one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>two septillion , six hundred one sextillion , ...</td>\n",
       "      <td>six octillion , three hundred thirty-four sept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>fifty-two trillion , one hundred ninety-seven ...</td>\n",
       "      <td>two hundred octillion , five hundred ten septi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unique_ID                                              text1  \\\n",
       "0          0  eight hundred seventy-eight nonillion , four h...   \n",
       "1          1  two hundred two quadrillion , five hundred for...   \n",
       "2          2  sixty-two duodecillion , six hundred twenty-tw...   \n",
       "3          3  two septillion , six hundred one sextillion , ...   \n",
       "4          4  fifty-two trillion , one hundred ninety-seven ...   \n",
       "\n",
       "                                               text2  \n",
       "0  twenty-one octillion , one hundred three septi...  \n",
       "1  one octillion , one septillion , five sextilli...  \n",
       "2                                         twenty-one  \n",
       "3  six octillion , three hundred thirty-four sept...  \n",
       "4  two hundred octillion , five hundred ten septi...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Create a function to Lemmatize\n",
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer() # Instantiate lemmatizer\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text] # Lemmatize\n",
    "    lemmatized_string = \" \".join(lemmatized)\n",
    "    return lemmatized_string\n",
    "\n",
    "df['text1'] = df['text1'].apply(lemma)\n",
    "df['text2'] = df['text2'].apply(lemma)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two hundred two quadrillion , five hundred forty trillion , two hundred thirty-two billion , seven hundred fifty million , one hundred sixty-two thousand twenty-five'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking all functions have worked\n",
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèóÔ∏èPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
